{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a6de8-52f9-4609-b5bf-09cf48d042c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f521e1-d66c-4ac0-9705-6a388850adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=資料科學&expansionType=area,spec,com,job,wf,wktm&order=12&asc=0&page=1&mode=s&jobsource=2018indexpoc&langFlag=0&langStatus=0&recommendJob=1&hotJob=1\n",
      "抓職缺大數據中...\n",
      "寫入細節\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'job_other' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m     job_other \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;66;03m# 其他條件\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m寫入細節\u001b[39m\u001b[38;5;124m'\u001b[39m)    \n\u001b[0;32m     79\u001b[0m job_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m職缺\u001b[39m\u001b[38;5;124m'\u001b[39m:job_name, \n\u001b[0;32m     80\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m公司名稱\u001b[39m\u001b[38;5;124m'\u001b[39m:job_company, \n\u001b[0;32m     81\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m地址\u001b[39m\u001b[38;5;124m'\u001b[39m:job_loc, \n\u001b[0;32m     82\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m薪資\u001b[39m\u001b[38;5;124m'\u001b[39m:job_pay, \n\u001b[0;32m     83\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m連結\u001b[39m\u001b[38;5;124m'\u001b[39m:job_content_link, \n\u001b[0;32m     84\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m工作內容\u001b[39m\u001b[38;5;124m'\u001b[39m:job_content, \n\u001b[0;32m     85\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m工作經驗\u001b[39m\u001b[38;5;124m'\u001b[39m:job_dreqire, \n\u001b[0;32m     86\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m科系要求\u001b[39m\u001b[38;5;124m'\u001b[39m:job_mreqire, \n\u001b[0;32m     87\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m擅長工具\u001b[39m\u001b[38;5;124m'\u001b[39m:job_goodat1, \n\u001b[1;32m---> 88\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m其他條件\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mjob_other\u001b[49m}\n\u001b[0;32m     90\u001b[0m all_job_datas\u001b[38;5;241m.\u001b[39mappend(job_data)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m資料寫入完成\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'job_other' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import random, time\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "delay_choices = [1,2,3,4]#延遲秒數\n",
    "delay = random.choices(delay_choices)#隨機選取秒數\n",
    "\n",
    "ua = UserAgent()\n",
    "# proxy = get_random_proxy()\n",
    "# proxies1 = 'https://' + proxy[0]\n",
    "# proxies2 = 'http://' + proxy[0]\n",
    "# proxies3 = {'http': proxies2, 'https':proxies1}\n",
    "\n",
    "url_a = 'https://www.104.com.tw/jobs/search/?ro=0&keyword=資料科學&expansionType=area,spec,com,job,wf,wktm&order=12&asc=0&page='\n",
    "url_b = '&mode=s&jobsource=2018indexpoc&langFlag=0&langStatus=0&recommendJob=1&hotJob=1'\n",
    "\n",
    "all_job_datas = []\n",
    "\n",
    "for page in range(1,54):\n",
    "    url = url_a+ str(page)+url_b\n",
    "    print(url)\n",
    "    headers = {'Referer': 'https://www.104.com.tw/job/6vrlf',\n",
    "              'User-Agent': ua.random}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    jobs = soup.find_all('article',class_='js-job-item')\n",
    "    \n",
    "    for job in jobs:\n",
    "        job_name = job.find('a', class_='js-job-link').text\n",
    "        job_company = job.get('data-cust-name')\n",
    "        job_loc = job.find('ul', class_='job-list-intro').find('li').text\n",
    "        job_pay = job.find('span',class_='b-tag--default').text\n",
    "        job_content_link = job.find('a', class_='js-job-link').get('href')\n",
    "        all_job_link = ('https:'+job_content_link)\n",
    "        \n",
    "        print('抓職缺大數據中...')\n",
    "        \n",
    "        header = {'Referer': 'https://www.104.com.tw/jobs/search/'}\n",
    "        time.sleep(1)\n",
    "        response_link = requests.get(all_job_link, headers = header)\n",
    "        time.sleep(1)\n",
    "        soup_link = BeautifulSoup(response_link.text, 'html.parser')\n",
    "        try:\n",
    "            job_content = soup_link.find('p', class_='job-description__content').text #工作內容\n",
    "        except:\n",
    "            job_content = ''\n",
    "        job_require_all = soup_link.find_all('div', class_= 'dialog container-fluid bg-white rounded job-requirement mb-4 pt-6 pb-6')\n",
    "        job_goodat_all = soup_link.find_all('a', class_='tools')\n",
    "        job_other_all = soup_link.find_all('p', class_='m-0 r3 w-100')\n",
    "        \n",
    "        job_goodat1 = []\n",
    "        list.clear(job_goodat1)\n",
    "        \n",
    "        # for link in all_job_link:\n",
    "        #     url = link\n",
    "        #     header = {'Referer': 'https://www.104.com.tw/jobs/search/'}\n",
    "        #     response_link = requests.get(url, headers = header)\n",
    "        #     time.sleep(1)\n",
    "        #     soup_link = BeautifulSoup(response_link.text, 'html.parser')\n",
    "        #     job_content = soup_link.find('p', class_='job-description__content').text #工作內容\n",
    "        #     job_require_all = soup_link.find_all('div', class_= 'dialog container-fluid bg-white rounded job-requirement mb-4 pt-6 pb-6')\n",
    "        #     job_goodat_all = soup_link.find_all('a', class_='tools')\n",
    "        #     job_other_all = soup_link.find_all('p', class_='m-0 r3 w-100')\n",
    "        #     print('抓detail中...')\n",
    "            \n",
    "        for i in job_require_all:\n",
    "            job_exp = i.p.text.strip()#工作經歷\n",
    "            job_dreqire = i.find_all('p')[1].text.strip()#學歷要求\n",
    "            job_mreqire = i.find_all('p')[2].text.strip()#科系要求\n",
    "        for i in job_goodat_all:\n",
    "            job_goodat = i.text #擅長工具\n",
    "            job_goodat1.append(job_goodat)\n",
    "        for i in job_other_all:\n",
    "            job_other = i.text # 其他條件\n",
    "                \n",
    "        print('寫入細節')    \n",
    "        job_data = {'職缺':job_name, \n",
    "                    '公司名稱':job_company, \n",
    "                    '地址':job_loc, \n",
    "                    '薪資':job_pay, \n",
    "                    '連結':job_content_link, \n",
    "                    '工作內容':job_content, \n",
    "                    '工作經驗':job_dreqire, \n",
    "                    '科系要求':job_mreqire, \n",
    "                    '擅長工具':job_goodat1, \n",
    "                    '其他條件':job_other}\n",
    "        \n",
    "        all_job_datas.append(job_data)\n",
    "        print('資料寫入完成')\n",
    "        time.sleep(delay[0])       \n",
    "    time.sleep(delay[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e7322-83d3-4915-8cb5-b1da4a178745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
